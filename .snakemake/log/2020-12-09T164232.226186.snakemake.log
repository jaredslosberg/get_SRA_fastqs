Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	get_SRA
	1

[Wed Dec  9 16:42:32 2020]
rule get_SRA:
    input: SRP258962_out/SRP258962_accession_list.txt
    output: logs/SRP258962_test.log
    log: logs/SRP258962_test.log
    jobid: 0
    wildcards: project_accession=SRP258962

RuleException in line 23 of /home/jared/workflows/get_SRP_fastqs/Snakefile:
NameError: The name 'print $0"' is unknown in this context. Please make sure that you defined that variable. Also note that braces not used for variable access have to be escaped by repeating them, i.e. {{print $1}}
  File "/home/jared/anaconda3/envs/snakemake/lib/python3.7/site-packages/snakemake/executors/__init__.py", line 115, in run_jobs
  File "/home/jared/anaconda3/envs/snakemake/lib/python3.7/site-packages/snakemake/executors/__init__.py", line 402, in run
  File "/home/jared/anaconda3/envs/snakemake/lib/python3.7/site-packages/snakemake/executors/__init__.py", line 203, in _run
  File "/home/jared/anaconda3/envs/snakemake/lib/python3.7/site-packages/snakemake/executors/__init__.py", line 131, in _run
  File "/home/jared/anaconda3/envs/snakemake/lib/python3.7/site-packages/snakemake/executors/__init__.py", line 137, in printjob
